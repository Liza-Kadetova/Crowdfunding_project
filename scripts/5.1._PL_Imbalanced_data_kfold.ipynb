{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Аугментация данных\n",
    "Ранее в рамках проекта нами была обучена модель для классификации текстов благотворительных сборов. Модель получает текст и должна предсказывать его тему: например, лечение детей, помощь животным и так далее. Модель в целом показывает удовлетворительные результаты, учитывая сложность задачи из-за большой лексической близости текстов, маленького объема данных и их несбалансированность. В этой части исследования попробуем улучшить показатели за счет методов компенсации несбалансированности данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 758 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.23 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.18.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.0.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.7.0 imblearn-0.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold \n",
    "# можно импортировать просто model_selection целиком, тогда при использ. сплита нужно писать ... = model_selection.train_test_split*\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "# можно импортировать linear_model целиком, тогда дальше нужно писать ... = linear_model.LogisticRegression()*\n",
    "\n",
    "# *это два разных способа импортировать эту функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from string import digits\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/liza/PycharmProjects/Planeta_project/plset_ver_010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "активизм_просвещение_профилактика\n",
      "бездомные_кризис\n",
      "взрослые_лечение_реабилитация\n",
      "дети_лечение_реабилитация\n",
      "животные\n",
      "заключенные\n",
      "малоимущие_бедность\n",
      "мечты_подарки_праздники\n",
      "наука_история_культура\n",
      "паллиатив_уход\n",
      "пожилые_ветераны\n",
      "развитие_нко_инфраструктура\n",
      "семейный_кризис\n",
      "сироты_дети_из_неблагополучных семей\n",
      "социализация_возможности\n",
      "экология\n"
     ]
    }
   ],
   "source": [
    "# Уникальные названия категорий в датасете\n",
    "\n",
    "for topic in np.unique(df['Category']):\n",
    "                print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 = 4%   активизм_просвещение_профилактика\n",
      "37 = 2%   бездомные_кризис\n",
      "71 = 3%   взрослые_лечение_реабилитация\n",
      "535 = 26%   дети_лечение_реабилитация\n",
      "245 = 12%   животные\n",
      "6 = 0%   заключенные\n",
      "66 = 3%   малоимущие_бедность\n",
      "92 = 5%   мечты_подарки_праздники\n",
      "10 = 0%   наука_история_культура\n",
      "57 = 3%   паллиатив_уход\n",
      "44 = 2%   пожилые_ветераны\n",
      "84 = 4%   развитие_нко_инфраструктура\n",
      "28 = 1%   семейный_кризис\n",
      "262 = 13%   сироты_дети_из_неблагополучных семей\n",
      "395 = 19%   социализация_возможности\n",
      "21 = 1%   экология\n"
     ]
    }
   ],
   "source": [
    "# Смотрим соотношение данных в датасете, всего 2038 экземляров, очень неравномерное распределение\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for k in np.unique(df['Category']):\n",
    "    volume = len(df[df['Category']==k])\n",
    "    volume_percent = round(volume*100/2038)\n",
    "    print(f'{volume} = {volume_percent}%   {k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "На предыдущем этапе мы попробовали разные классификаторы и гиперапаметры. Лучшие результаты показала LogisticRegression без доп. параметров, за исключением max_iter, т.к. при значении по умолчанию модель просто не справляется с подсчетами. Если несколько раз перезапустить split (без random_state) и обучение, оценки варьируются от запуска к запуску. **Примерные значения, которые принимаем как baseline:**\n",
    "\n",
    "accuracy: 0.78\\\n",
    "macro avg: 0.60\\\n",
    "weighted avg: 0.77 \n",
    "\n",
    "+\\\\-0.04 в каждой метрике"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Повторим процесс обучения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заготовка функций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend(['это', '–', '-', 'фонд', 'наш', 'помощь', 'помогать',\n",
    "                   'помочь', 'поддержать', 'поддержка', 'средство', 'который', 'весь',\n",
    "                   'благотворительный', 'пожертвовать', 'пожертвование', 'деньги', 'рубль', 'год', 'день', 'тысяча',\n",
    "                   'ваш', 'сегодня', 'завтра', 'этот', 'дать', 'проект', 'свой' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для предобработки текстов\n",
    "\n",
    "def prep(text):\n",
    "    clean_text = text.translate(str.maketrans('', '', '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~«»№!—'))\n",
    "    clean_text = clean_text.translate(str.maketrans('', '', digits)) # удаляем цифры\n",
    "    clean_text = re.sub(\"-\", \" \", clean_text) # меняем тире на пробелы, т.к. maketrans их почему-то не выхватывает\n",
    "    #clean_text = re.sub(\"[a-zA-Z]\", \"\", clean_text)  # исключаем слова латиницей\n",
    "    clean_text = clean_text.lower() # приводим все к нижнему регистру\n",
    "    clean_text = clean_text.split() # разбиваем (токенизируем) по словам\n",
    "    \n",
    "    # можно возвращать слова без лемматизации\\стемминга\n",
    "    #words = [word for word in clean_text if word not in stop_words]\n",
    "    #return words\n",
    "    \n",
    "    lemmas = [morph_analyzer.parse(word)[0].normal_form for word in clean_text]\n",
    "    lemmas = [word for word in lemmas if word not in stop_words]\n",
    "    return lemmas\n",
    "    \n",
    "    #ниже - альтернатива лемматицации, можно их переключать (за/раскомменчивать)\n",
    "    #stemmer = RussianStemmer()\n",
    "    #stemmed_words = [stemmer.stem(word) for word in clean_text]\n",
    "    #return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь для параметра class_weight для Лог. регр.\n",
    "\n",
    "topic_weights = {\n",
    "     'активизм_просвещение_профилактика': 0.08,\n",
    "     'бездомные_кризис': 0.08,\n",
    "     'взрослые_лечение_реабилитация': 0.08,\n",
    "     'дети_лечение_реабилитация': 0.01,\n",
    "     'животные': 0.01,\n",
    "     'заключенные': 0.08,\n",
    "     'малоимущие_бедность': 0.08,\n",
    "     'мечты_подарки_праздники': 0.08,\n",
    "     'наука_история_культура': 0.08,\n",
    "     'паллиатив_уход': 0.08,\n",
    "     'пожилые_ветераны': 0.08,\n",
    "     'развитие_нко_инфраструктура': 0.08,\n",
    "     'семейный_кризис': 0.08,\n",
    "     'сироты_дети_из_неблагополучных семей': 0.01,\n",
    "     'социализация_возможности': 0.01,\n",
    "     'экология': 0.08}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Получение признаков**\\\n",
    "При прошлых попытках обучения CountVectorizer показал себя лучше TfidfVectorizer, поэтому оставляем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 1.09 s, total: 3min 22s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vec = CountVectorizer(tokenizer=prep) \n",
    "bag_of_words = vec.fit_transform(df.Description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Деление на выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.Category, stratify = df.Category, random_state=42) #, test_size=0.15)\n",
    "\n",
    "#stratification means that the train_test_split method returns training and test subsets that have the same proportions of class labels as the input dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "   активизм_просвещение_профилактика       0.65      0.62      0.63        21\n",
      "                    бездомные_кризис       0.80      0.89      0.84         9\n",
      "       взрослые_лечение_реабилитация       0.41      0.39      0.40        18\n",
      "           дети_лечение_реабилитация       0.89      0.81      0.85       134\n",
      "                            животные       0.97      0.98      0.98        61\n",
      "                         заключенные       0.00      0.00      0.00         1\n",
      "                 малоимущие_бедность       0.53      0.59      0.56        17\n",
      "             мечты_подарки_праздники       0.68      0.65      0.67        23\n",
      "              наука_история_культура       0.00      0.00      0.00         3\n",
      "                      паллиатив_уход       0.86      0.86      0.86        14\n",
      "                    пожилые_ветераны       0.69      0.82      0.75        11\n",
      "         развитие_нко_инфраструктура       0.27      0.33      0.30        21\n",
      "                     семейный_кризис       0.62      0.71      0.67         7\n",
      "сироты_дети_из_неблагополучных семей       0.83      0.73      0.77        66\n",
      "            социализация_возможности       0.69      0.83      0.76        99\n",
      "                            экология       1.00      0.40      0.57         5\n",
      "\n",
      "                            accuracy                           0.76       510\n",
      "                           macro avg       0.62      0.60      0.60       510\n",
      "                        weighted avg       0.76      0.76      0.76       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=5000, class_weight=topic_weights) # опционально (почти не влияет на рез.): C=0.02, class_weight=topic_weights\n",
    "clf = lr.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬆︎⬆︎⬆︎ Выше мы попробовали еще несколько параметров, которые не настраивали раньше\n",
    "1. Для компенсации небольшого количества данных можно **изменять пропорции разделения на train и test (параметр test_size в split)**, чтобы увеличить объем данных для обучения. \n",
    "\n",
    "2. Также можно **в LogisticRegression в class_weight подать словарь**, который будет задавать веса классов. Class_weight, default: none, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)). With a dictionary it penalizes mistakes in samples of class with class_weight. So higher class-weight means we want to put more emphasis on a class. If say class 0 is 19 times more frequent than class 1, we should increase the class_weight of class 1 relative to class 0, say {0:.1, 1:.9}.\n",
    "These weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified (sample_weight: Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight).\\\n",
    "Словарь задан выше. Параметр \"включается\" раскомментированием в строке. \n",
    "\n",
    "Итог:\\\n",
    "Стойкого улучшения ни то, ни другое не дает, метрики всегда варьируются в пределах известного периода и скорее зависят от конкретного случая разбиения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Under-sampling и over-sampling\n",
    "\n",
    "Для работы с несбалансированными данными нужно увеличить количество одних примеров или уменьшить количество других. Для этого существуют различные техники аугментации (увеличения, усиления) данных. В Python для этих целей есть библиотека imblearn (imbalanced-learn). Инструменты для аугментации: under-sampling, over-sampling и их комбинация.\n",
    " \n",
    "**Under-sampling** уравновешивает данные за счет уменьшения размера превалирующего класса. Этот метод разумно использовать, когда количество данных достаточно велико, иначе есть риск остаться и вовсе без обучающих примеров.\n",
    "\n",
    "**Over-sampling** применяется, когда данных недостаточно или количество экземпляров в миноритарном классе очень мало. При применении этой техники балансировка данных происходит за счет увеличения количества экземпляров в миноритарном классе. Новые элементы генерируются за счет: повторения, бутстрэппинга, SMOTE (Synthetic Minority Over-Sampling Technique) или ADASYN (Adaptive synthetic sampling).\n",
    "\n",
    "[Источник](https://github.com/PragmaticsLab/NLP-course-AMI/blob/dev/seminars/sem3_classification.ipynb)\n",
    "\n",
    "В нашем случае данных мало, поэтому будем использовать over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для обучения модели\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid): # получает метод классификации, учебный вектор признаков, правильные лейблы к нему, проверочный вектор признаков\n",
    "    classifier.fit(feature_vector_train, label) # fit запоминает вектор конкретного текста (документа) + даем соответствующие каждому лейблы\n",
    "    predictions = classifier.predict(feature_vector_valid) # просим предсказать лейблы для текстов из тестовой выборки\n",
    "    #return f1_score(y_test, predictions, average='weighted', zero_division=0) # возвращает оценку после соотнесения предсказанных лейблов с правильными из тестовой выборки\n",
    "    return classification_report(y_test, predictions, zero_division=0) # можно переключать вид оценки (полный или только f-score или любой другой из sklearn metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечания к функции обучения** ⬆︎\n",
    "\n",
    "* Точность в качестве метрики работает хорошо только на сбалансированных наборах данных, поэтому для оценки результатов работы алгоритма будем использовать F-меру. F-мера (F1 score) представляет собой совместную оценку точности и полноты. Вычисляется по формуле: F-мера = 2 * Точность * Полнота / (Точность + Полнота). Should be used **to compare classifier models**, not global accuracy.\n",
    "\n",
    "* Выбор вывода оценки. С помощью комментирования # можно переключаться межу полным отчетом и только f1-score. Для f1-score можно менять тип average (по умолчанию это binary, но он не работает на мультиклассовом обучении):\\\n",
    "    **'micro':**\n",
    "    Calculate metrics globally by counting the total true positives, false negatives and false positives.\\\n",
    "    **'macro':**\n",
    "    Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\\\n",
    "    **'weighted':**\n",
    "    Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\\\n",
    "    **'samples':**\n",
    "    Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score).\n",
    "\n",
    "* Zero_division. Sets the value to return when there is a zero division. If set to “warn”, this acts as 0, but warnings are also raised. If we request an **average** of the score, we must take into account that a score of 0 may be included in the calculation and scikit-learn will show a warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "**RandomOverSampler**\\\n",
    "Случайным образом дублируются некоторые элементы из миноритарного класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression ROS:\n",
      "\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "   активизм_просвещение_профилактика       0.33      0.15      0.21        13\n",
      "                    бездомные_кризис       0.83      1.00      0.91         5\n",
      "       взрослые_лечение_реабилитация       0.80      0.36      0.50        11\n",
      "           дети_лечение_реабилитация       0.84      0.89      0.86        80\n",
      "                            животные       0.90      1.00      0.95        37\n",
      "                         заключенные       0.00      0.00      0.00         1\n",
      "                 малоимущие_бедность       0.62      0.80      0.70        10\n",
      "             мечты_подарки_праздники       0.69      0.79      0.73        14\n",
      "              наука_история_культура       0.00      0.00      0.00         1\n",
      "                      паллиатив_уход       1.00      0.89      0.94         9\n",
      "                    пожилые_ветераны       1.00      0.57      0.73         7\n",
      "         развитие_нко_инфраструктура       0.36      0.38      0.37        13\n",
      "                     семейный_кризис       0.67      0.50      0.57         4\n",
      "сироты_дети_из_неблагополучных семей       0.79      0.87      0.83        39\n",
      "            социализация_возможности       0.83      0.83      0.83        59\n",
      "                            экология       1.00      1.00      1.00         3\n",
      "\n",
      "                            accuracy                           0.79       306\n",
      "                           macro avg       0.67      0.63      0.63       306\n",
      "                        weighted avg       0.78      0.79      0.78       306\n",
      "\n",
      "CPU times: user 1min 21s, sys: 8.19 s, total: 1min 29s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ros = RandomOverSampler(random_state=777)\n",
    "ros_xtrain, ros_ytrain = ros.fit_sample(X_train, y_train) #пропускаем тренировочные тексты и лейблы через ROS\n",
    "accuracyROS = train_model(LogisticRegression(max_iter=5000, random_state=0, class_weight=topic_weights),ros_xtrain, ros_ytrain, X_test) # вызываем функцию\n",
    "print (\"Logistic regression ROS:\\n\\n\", accuracyROS) # выводим оценку, заложенную в функции train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "**SMOTE**\\\n",
    "Алгоритм SMOTE основан на идее генерации некоторого количества искусственных примеров, которые были бы «похожи» на имеющиеся в миноритарном классе, но при этом не дублировали их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression SMOTE:\n",
      "\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "   активизм_просвещение_профилактика       0.50      0.52      0.51        21\n",
      "                    бездомные_кризис       0.67      0.89      0.76         9\n",
      "       взрослые_лечение_реабилитация       0.40      0.33      0.36        18\n",
      "           дети_лечение_реабилитация       0.85      0.83      0.84       134\n",
      "                            животные       0.97      0.98      0.98        61\n",
      "                         заключенные       0.00      0.00      0.00         1\n",
      "                 малоимущие_бедность       0.69      0.53      0.60        17\n",
      "             мечты_подарки_праздники       0.86      0.52      0.65        23\n",
      "              наука_история_культура       0.00      0.00      0.00         3\n",
      "                      паллиатив_уход       0.92      0.86      0.89        14\n",
      "                    пожилые_ветераны       0.71      0.91      0.80        11\n",
      "         развитие_нко_инфраструктура       0.50      0.33      0.40        21\n",
      "                     семейный_кризис       0.62      0.71      0.67         7\n",
      "сироты_дети_из_неблагополучных семей       0.80      0.71      0.75        66\n",
      "            социализация_возможности       0.66      0.86      0.75        99\n",
      "                            экология       0.75      0.60      0.67         5\n",
      "\n",
      "                            accuracy                           0.76       510\n",
      "                           macro avg       0.62      0.60      0.60       510\n",
      "                        weighted avg       0.76      0.76      0.75       510\n",
      "\n",
      "CPU times: user 1min 11s, sys: 7.84 s, total: 1min 19s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm = SMOTE(random_state=777, k_neighbors=3)\n",
    "sm_xtrain, sm_ytrain = sm.fit_sample(X_train, y_train)\n",
    "accuracySMOTE = train_model(LogisticRegression(max_iter=5000, random_state=0), sm_xtrain, sm_ytrain, X_test)\n",
    "print (\"Logistic regression SMOTE:\\n\\n\", accuracySMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "⬆︎⬆︎⬆︎ SMOTE may raise ValueError: \"Expected n_neighbors <= n_samples, but n_samples = 5, n_neighbors = 6.\\\n",
    "n_neighbors (parameter k_neighbors, default = 5) is the number of nearest neighbours to be used to construct synthetic samples. \n",
    "Суть проблемы в том, что в обучающей выборке в каком-то из классов оказывается меньше экземпляров, чем нужно для формирования новых синтетических экземпляров в соответствии с параметром k_neighbors. \n",
    "\n",
    "A few solutions for the problem:\n",
    "\n",
    "1. Calculate the minimum number of samples (n_samples) among the classes and select n_neighbors parameter of SMOTE class less or equal to n_samples. \n",
    "2. Use RandomOverSampler class which does not have a similar restriction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⬇︎⬇︎⬇︎ Еще одна настройка SMOTE - это sampling_strategy: в каких пропорциях создаются новые синтетические экз. классов. У класса SMOTE есть несколько встроенных определений, а можно подать словарь. When dict, the keys correspond to the targeted classes. The values correspond to the desired number of samples for each targeted class.\n",
    "\n",
    "Попробуем задать свой словарь. Желаемое количество экз. не должно быть меньше изначального количества в обучающей выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_dict = {\n",
    "     'активизм_просвещение_профилактика': 160,\n",
    "     'бездомные_кризис': 160,\n",
    "     'взрослые_лечение_реабилитация': 160,\n",
    "     'дети_лечение_реабилитация': 401,\n",
    "     'животные': 200,\n",
    "     'заключенные': 160,\n",
    "     'малоимущие_бедность': 160,\n",
    "     'мечты_подарки_праздники': 160,\n",
    "     'наука_история_культура': 160,\n",
    "     'паллиатив_уход': 160,\n",
    "     'пожилые_ветераны': 160,\n",
    "     'развитие_нко_инфраструктура': 160,\n",
    "     'семейный_кризис': 160,\n",
    "     'сироты_дети_из_неблагополучных семей': 200,\n",
    "     'социализация_возможности': 300,\n",
    "     'экология': 160}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression SMOTE:\n",
      "\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "   активизм_просвещение_профилактика       0.59      0.48      0.53        21\n",
      "                    бездомные_кризис       0.67      0.89      0.76         9\n",
      "       взрослые_лечение_реабилитация       0.40      0.33      0.36        18\n",
      "           дети_лечение_реабилитация       0.88      0.84      0.85       134\n",
      "                            животные       0.95      0.97      0.96        61\n",
      "                         заключенные       0.00      0.00      0.00         1\n",
      "                 малоимущие_бедность       0.64      0.53      0.58        17\n",
      "             мечты_подарки_праздники       0.81      0.57      0.67        23\n",
      "              наука_история_культура       0.00      0.00      0.00         3\n",
      "                      паллиатив_уход       0.86      0.86      0.86        14\n",
      "                    пожилые_ветераны       0.64      0.82      0.72        11\n",
      "         развитие_нко_инфраструктура       0.37      0.33      0.35        21\n",
      "                     семейный_кризис       0.57      0.57      0.57         7\n",
      "сироты_дети_из_неблагополучных семей       0.81      0.77      0.79        66\n",
      "            социализация_возможности       0.67      0.85      0.75        99\n",
      "                            экология       1.00      0.60      0.75         5\n",
      "\n",
      "                            accuracy                           0.76       510\n",
      "                           macro avg       0.62      0.59      0.59       510\n",
      "                        weighted avg       0.76      0.76      0.75       510\n",
      "\n",
      "CPU times: user 50.8 s, sys: 5.89 s, total: 56.7 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sm = SMOTE(sampling_strategy=strategy_dict, random_state=777, k_neighbors=4)\n",
    "sm_xtrain, sm_ytrain = sm.fit_sample(X_train, y_train)\n",
    "accuracySMOTE = train_model(LogisticRegression(max_iter=5000, random_state=0), sm_xtrain, sm_ytrain, X_test)\n",
    "print (\"Logistic regression SMOTE:\\n\\n\", accuracySMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "Результат: разницы нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "**ADASYN или ASMO**\\\n",
    "Adaptive synthetic minority oversampling.\n",
    "Сгенерировать искусственные записи в пределах отдельных кластеров на основе всех классов. Для каждого примера миноритарного класса находят m ближайших соседей, и на основе них (также как в SMOTE) создаются новые записи.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression ADASYN:\n",
      "\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "   активизм_просвещение_профилактика       0.52      0.57      0.55        21\n",
      "                    бездомные_кризис       0.67      0.89      0.76         9\n",
      "       взрослые_лечение_реабилитация       0.33      0.33      0.33        18\n",
      "           дети_лечение_реабилитация       0.86      0.82      0.84       134\n",
      "                            животные       0.95      1.00      0.98        61\n",
      "                         заключенные       0.00      0.00      0.00         1\n",
      "                 малоимущие_бедность       0.75      0.53      0.62        17\n",
      "             мечты_подарки_праздники       0.77      0.43      0.56        23\n",
      "              наука_история_культура       0.00      0.00      0.00         3\n",
      "                      паллиатив_уход       0.86      0.86      0.86        14\n",
      "                    пожилые_ветераны       0.64      0.82      0.72        11\n",
      "         развитие_нко_инфраструктура       0.46      0.29      0.35        21\n",
      "                     семейный_кризис       0.62      0.71      0.67         7\n",
      "сироты_дети_из_неблагополучных семей       0.79      0.70      0.74        66\n",
      "            социализация_возможности       0.66      0.86      0.75        99\n",
      "                            экология       0.75      0.60      0.67         5\n",
      "\n",
      "                            accuracy                           0.75       510\n",
      "                           macro avg       0.60      0.59      0.59       510\n",
      "                        weighted avg       0.75      0.75      0.74       510\n",
      "\n",
      "CPU times: user 1min 10s, sys: 7.25 s, total: 1min 17s\n",
      "Wall time: 27.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ad = ADASYN(random_state=777, n_neighbors=4)\n",
    "ad_xtrain, ad_ytrain = ad.fit_sample(X_train, y_train)\n",
    "accuracyADASYN = train_model(LogisticRegression(max_iter=5000, random_state=0), ad_xtrain, ad_ytrain, X_test)\n",
    "print (\"Logistic regression ADASYN:\\n\\n\", accuracyADASYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\n",
    "Результат: разницы нет. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Альтернативный способ кросс-валидации\n",
    "\n",
    "Кросс-валидация - это когда мы делим датасет на подсеты для train и test. train_test.split - один из типов кросс-валидации в sklearn. \n",
    "Еще один - **k-fold cross-validation**.\n",
    "\n",
    "Насколько я поняла, **это метод помогает не лучше обучить модель, а точнее оценить на небольшом датасете ее способности после обучения, т.к. мы несколько раз перетряхиваем данные и повторяем оценку.** \n",
    "\n",
    "Из википедии:\n",
    "\n",
    "Illustration of k-fold cross-validation when n = 12 observations and k = 3. After data is shuffled, a total of 3 models will be trained and tested.\n",
    "In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. The k results can then be averaged to produce a single estimation. The advantage of this method over repeated random sub-sampling (see below) is that all observations are used for both training and validation, and each observation is used for validation exactly once. 10-fold cross-validation is commonly used, but in general k remains an unfixed parameter.\n",
    "\n",
    "For example, setting k = 2 results in 2-fold cross-validation. In 2-fold cross-validation, we randomly shuffle the dataset into two sets d0 and d1, so that both sets are equal size (this is usually implemented by shuffling the data array and then splitting it in two). We then train on d0 and validate on d1, followed by training on d1 and validating on d0.\n",
    "\n",
    "When k = n (the number of observations), k-fold cross-validation is equivalent to leave-one-out cross-validation.\n",
    "\n",
    "In stratified k-fold cross-validation, the partitions are selected so that the mean response value is approximately equal in all the partitions. In the case of binary classification, this means that each partition contains roughly the same proportions of the two types of class labels.\n",
    "\n",
    "In repeated cross-validation the data is randomly split into k partitions several times. The performance of the model can thereby be averaged over several runs, but this is rarely desirable in practice.\n",
    "\n",
    "***\n",
    "It is a popular method because **it generally results in a less biased or less optimistic estimate of the model skill than other methods**, such as a simple train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для обучения модели, копия функции, описанной выше с изменениями: return f1_score(kf_y_test.....)\n",
    "\n",
    "def train_model_2(classifier, feature_vector_train, label, feature_vector_valid): # получает метод классификации, учебный вектор признаков, правильные лейблы к нему, проверочный вектор признаков\n",
    "    classifier.fit(feature_vector_train, label) # fit запоминает вектор конкретного текста (документа) + даем соответсвующие им лейблы\n",
    "    predictions = classifier.predict(feature_vector_valid) # просим теперь предсказать лейблы для текстов из тестовой выборки\n",
    "    return f1_score(kf_y_test, predictions, average='weighted', zero_division=0) # возвращает оценку после соотнесения предсказанных лейблов с правильными из тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7213958534233366\n",
      "0.8329895594601476\n",
      "0.8461618701482438\n",
      "0.7106169518265688\n",
      "0.8902255104940527\n",
      "0.7822482198106386\n",
      "0.7657016256886547\n",
      "0.7804311572500428\n",
      "0.7967710157680223\n",
      "0.736866820306718\n",
      "0.770622004862818\n",
      "0.67765909873203\n",
      "0.7509785089770742\n",
      "0.6959227811590519\n",
      "0.5935457957680179\n",
      "CPU times: user 27min 48s, sys: 2min 50s, total: 30min 38s\n",
      "Wall time: 10min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# KFold\n",
    "ros = RandomOverSampler(random_state=777)\n",
    "\n",
    "X = bag_of_words # векторизованные тексты\n",
    "y = df.Category # лейблы из датасета\n",
    "kf = KFold(n_splits=15) # вызов KFold, количество сплитов можно менять\n",
    "kf.get_n_splits(X)  # разбиваем\n",
    "#print(kf)\n",
    "for train_index, test_index in kf.split(X): # учим и оцениваем\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    kf_X_train, kf_X_test = X[train_index], X[test_index]\n",
    "    kf_y_train, kf_y_test = y[train_index], y[test_index]\n",
    "    kf_ros_xtrain, kf_ros_ytrain = ros.fit_sample(kf_X_train, kf_y_train)\n",
    "    kf_accuracyROS = train_model_2(LogisticRegression(max_iter=5000, random_state=0),kf_ros_xtrain, kf_ros_ytrain, kf_X_test)\n",
    "    print(kf_accuracyROS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7302526251017173\n",
      "0.8273778167983612\n",
      "0.8287180255217856\n",
      "0.6985739750445632\n",
      "0.8754106187929719\n",
      "0.745771633358549\n",
      "0.7648602268050531\n",
      "0.7733937117781529\n",
      "0.7829275681903968\n",
      "0.7035525228995968\n",
      "0.7740292652956718\n",
      "0.6594350277697194\n",
      "0.719034527150685\n",
      "0.6897324170400265\n",
      "0.5854170021258628\n",
      "CPU times: user 18min 2s, sys: 2min, total: 20min 3s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Пробуем то же самое без ROS\n",
    "\n",
    "X = bag_of_words # векторизованные тексты\n",
    "y = df.Category # лейблы из датасета\n",
    "kf = KFold(n_splits=15) # вызов KFold, количество сплитов можно менять\n",
    "kf.get_n_splits(X)  # разбиваем\n",
    "#print(kf)\n",
    "for train_index, test_index in kf.split(X): # учим и оцениваем\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    kf_X_train, kf_X_test = X[train_index], X[test_index]\n",
    "    kf_y_train, kf_y_test = y[train_index], y[test_index]\n",
    "    kf_accuracy = train_model_2(LogisticRegression(max_iter=5000, random_state=0),kf_X_train, kf_y_train, kf_X_test)\n",
    "    print(kf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат: При 15 раундах weighted f1-score может быть от 59% до 89%. Такой разброс показывают модели как с применением over-sampling (ROS), так и без. **В обоих случаях простое среднее всех 15 результатов - 74-75%**. Это соответствует наиболее частому результату, который мы получали ранее, комбинируя разные гиперпараметры и методы при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие итоги\n",
    "Добиться стойкого увеличения качества предсказания за счет борьбы с дисбалансом классов и настройки гиперпараметров не получается. Хотя результаты варьируется довольно сильно (как видно из отработки kfold - в приделах 30%!), достижение наилучших показателей (самый высокий - 89%) на практике происходит случайно: в процессе многократного перезапуска одной и той же комбинации векторизатора, сплита и классификатора, а не за счет контролируемого изменения отдельных настроек. \n",
    "\n",
    "По всей видимости, на имеющихся данных качество обучения/предсказания зависит от того, как случайным образом разбились данные на обучающую и тестовую выборку (условно говоря, насколько модели \"повезло на экзамене\"). А повышать качество обучения для достижения стабильных результатов нужно, вероятно, за счет работы с самими данными: \n",
    "1. Обогощать данными миноритарные классы\n",
    "2. Возможно - пересматривать экстралингвистический подход к категоризации\n",
    "3. Возможно - искусственно делить тексты на несколько текстов, т.к. они сравнительно объемные (больше короткой новостной заметки или твита)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
